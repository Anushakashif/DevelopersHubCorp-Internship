# -*- coding: utf-8 -*-
"""bankchurnmodeling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WYpbBxW5ozilQP5zMFwYPeZctjBsafhh

## Problem Statement

### Identify customers who are likely to leave the bank
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Splitting the data
from sklearn.model_selection import train_test_split

# Scaling the data - normalization and encoding
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler

# Oversampling technique for imbalance
from imblearn.over_sampling import SMOTE

# My predicting model
from sklearn.ensemble import RandomForestClassifier

# Evaluation metrics
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

# Evaluation plots
from yellowbrick.classifier import DiscriminationThreshold, PrecisionRecallCurve

df = pd.read_csv("/content/Customer-Churn-Records.csv")
df

df.head()

df.drop('Complain', axis=1, inplace=True)
# I will remove 'Complain' feature, since it is very similar to target variable 'Exited'. If I use it will definetely get perfect score as they are highly correlated.

df.describe(include="object")

df.info()

df.duplicated().sum()

df.columns

df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)

target = ['Exited']
cat_col = ['Geography', 'Gender', 'Card Type', 'Satisfaction Score', 'IsActiveMember', 'HasCrCard']
num_col = [col for col in df if col not in (cat_col+target)]

x = df.drop(columns=["Exited"])
y = df["Exited"]

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)

"""### EDA"""

plt.figure(figsize=(12, 5))
sns.countplot(x=y_train, color='darkred')

plt.title("Exited Distribution")
plt.xlabel("Exited")
plt.ylabel("Count")

plt.show()

display(y_train.value_counts(normalize=True))

# Almost 80% of data is churn.

# Distribution of categorical columns
plt.figure(figsize=(15, 10))
for i, col in enumerate(cat_col):
  plt.subplot(3, 3, i + 1)
  sns.countplot(data= df, x = col, hue=col, palette ='Set2', order = df[col].value_counts().index, legend=False)
  plt.title(f"Distribution of {col}")

plt.tight_layout()
plt.subplots_adjust(hspace=0.5, wspace=0.3)
plt.show()

sns.set_style("darkgrid")
plt.figure(figsize=(30,15))
for i, col in enumerate(num_col):
  plt.subplot(3, 4, i + 1)
  X_train[[col]].boxplot(fontsize=20)
  plt.title(f"Skewness: {np.round(X_train[col].skew(),2)}\n Kurtosis: {np.round(X_train[col].kurt(),2)}, fontdict={'fontsize':22}")

plt.tight_layout()
plt.show()

corr = X_train[num_col].corr()

plt.figure(figsize=(25,12))
mask=np.tril(np.ones_like(corr))
sns.heatmap(corr, annot=True, fmt=".2f", mask=mask, square=True)
plt.show()

# Nothing is highly correlated.
# Balance and NumOfProducts is highly negative correlated

fig, axes = plt.subplots(2, 3, figsize=(18, 8))
axes = axes.flatten()

for i, col in enumerate(cat_col):
    if col in X_train.columns:
        sns.countplot(
            x=col,
            hue=y_train,
            data=X_train,
            ax=axes[i]
        )
        axes[i].set_title(f"{col} vs Exited", fontsize=14)
        axes[i].tick_params(axis='x', rotation=0)
        axes[i].legend(title="Exited")

# Remove empty subplots if any
for j in range(i + 1, len(axes)):
    axes[j].axis('off')

fig.tight_layout()
fig.subplots_adjust(hspace=0.4, wspace=0.3)
plt.show()

# Customers from Germany show the highest churn, while Spain has the lowest churn rate.
# Female customers churn more frequently than male customers.
# Non Active Members churn more than active

"""## Preprocessing

### 1. one hot encoding to nominal categorical features
### 2. mapping the ordinal categorical features that need to be mapped
### 3. min max scaling the data

## One hot encoding
"""

nominal_cat_feats = ['Geography', 'Gender']
ordinal_cat_feats = ['Card Type']
numerical_feats = [
    col for col in X_train.columns
    if col not in nominal_cat_feats + ordinal_cat_feats
]

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler

preprocessor = ColumnTransformer(
    transformers=[
        ('nominal', OneHotEncoder(handle_unknown='ignore'), nominal_cat_feats),
        ('ordinal', OrdinalEncoder(
            categories=[['SILVER', 'GOLD', 'PLATINUM', 'DIAMOND']]
        ), ordinal_cat_feats),
        ('num', MinMaxScaler(), numerical_feats)
    ]
)

X_train_prepared = preprocessor.fit_transform(X_train)
X_test_prepared  = preprocessor.transform(X_test)

from imblearn.over_sampling import SMOTE

sm = SMOTE(
    sampling_strategy='auto',
    random_state=0,
    k_neighbors=5
)

X_res, y_res = sm.fit_resample(X_train_prepared, y_train)

rf = RandomForestClassifier(random_state=42)
rf.fit(X_res, y_res)

preds = rf.predict(X_test_prepared)

from sklearn.metrics import f1_score, recall_score, precision_score, classification_report

print('F-measure Random Forest test:', f1_score(y_test, preds, pos_label=1))
print('Recall Random Forest test:', recall_score(y_test, preds, pos_label=1))
print('Precision Random Forest test:', precision_score(y_test, preds))

print(classification_report(y_test, preds))

from yellowbrick.classifier import DiscriminationThreshold

visualizer = DiscriminationThreshold(
    rf,
    n_trials=1,
    cv=0.5,
    argmax='fscore',
    random_state=0,
    is_fitted='auto',
    exclude="queue_rate"
)

visualizer.fit(X_res, y_res)
visualizer.score(X_test_prepared, y_test)
visualizer.show()